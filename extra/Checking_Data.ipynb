{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "id": "0dq-i1Bfls5v"
   },
   "source": [
    "# Workbook 03 - Dimension Reduction\n",
    "by [David Elliott](https://eldave93.netlify.app/)\n",
    "\n",
    "1. [Workspace Setup](#setup)\n",
    "\n",
    "2. [Problem Understanding](#problem)\n",
    "\n",
    "3. [Data Pre-Processing/EDA](#eda)\n",
    "   \n",
    "__Notes__\n",
    "- Still experimenting with what dataset might be a good shout to demo this...\n",
    "- The divorse seems the model is too good from the beginning, but the data is interesting.\n",
    "- Cars seems like a good shout as improvments are minimal. Could look at categorical features as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Workspace Setup\n",
    "\n",
    "Before downloading any data we should think about our workspace. It is assumed if you have made it this far you have already got your workspace setup. There are two ways of using these notebooks. The first is to use Google Colab, which is a website that allows you to write and execute python code through the browser. The second is a local workspace (e.g. Anaconda)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.A. Google Colab\n",
    "If you are not using google colab then you can skip this section. \n",
    "\n",
    "If you are using colab we will first need to have the libaries for the runtime and files associated with this workbook uploaded to the temporary file store. You also need to set the working directory to be a local version of the workshop repository. This is so all the data, images, and scripts for displaying the solutions works. This is located on the temporary file store associated with this colabs runtime. The below code will do all this for you.\n",
    "\n",
    "__Required:__ After running this code make sure to restart the runtime to ensure everything works correctly (Runtime > Restart runtime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab is not being used\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    COLAB=True\n",
    "    \n",
    "    # set the workbook code\n",
    "    WORKSHOP_NAME = \"03-dimension-reduction\"\n",
    "    # set the folder name\n",
    "    FOLDER_NAME = \"machine-learning-workbooks-main\"\n",
    "\n",
    "    # check if the environment is already setup to avoid repeating this after \n",
    "    # restarting the runtime\n",
    "    if not os.path.exists(FOLDER_NAME):\n",
    "        # get the zip of the workbooks\n",
    "        !wget https://github.com/Eldave93/machine-learning-workbooks/archive/refs/heads/main.zip\n",
    "        # unzip the file\n",
    "        !unzip main.zip\n",
    "        # install the libaries\n",
    "        !{sys.executable} -m pip install -r ./{FOLDER_NAME}/scripts/requirements.txt\n",
    "          \n",
    "    print(\"Setting working directory to:\")\n",
    "    %cd ./{FOLDER_NAME}/{WORKSHOP_NAME}\n",
    "    \n",
    "except:\n",
    "    COLAB=False\n",
    "    print(\"Colab is not being used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Packages\n",
    "\n",
    "If your using a local workspace you will need all the following packages to run this notebook. If you do not already have them, or you want to ensure you are using the same versions as used when created, you could run `!{sys.executable} -m pip install -r ../scripts/requirements.txt` to install them for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # locating directories\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings # prevent warnings\n",
    "\n",
    "sys.path.append('../scripts') # add scripts to the path for use later\n",
    "sns.set(rc={'figure.figsize': (14, 8)}) # For plot sizes\n",
    "np.random.seed(42)  # to make this notebook's output identical at every run\n",
    "\n",
    "# colours for print()\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Displaying solutions\n",
    "\n",
    "The solutions are activated using a new .txt file which can be put in the workbook folder (e.g. `03-dimension-reduction`). Please put in a request for access.\n",
    "\n",
    "If you have access to the solutions, the following cell will create clickable buttons under each exercise, which will allow you to reveal the solutions.\n",
    "\n",
    "__Notes__\n",
    "\n",
    "- This method was created by [Charlotte Desvages](https://charlottedesvages.com/).\n",
    "- This may not work if you don't have the same version of `IPython.display` as the machine that created them:\n",
    "    ```\n",
    "    ImportError: cannot import name 'Code' from 'IPython.display' (/usr/local/lib/python3.7/dist-packages/IPython/display.py)\n",
    "    ```\n",
    "    If so run the auto-install above or manually run `!pip install ipython==7.20`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News pop\n",
    "__TODO:__ maybe this data will be a good one to look at NLP? You could recreate the metrics and compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download from the sourse\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "if not os.path.exists(\"./Data/OnlineNewsPopularity.zip\"):\n",
    "    r = requests.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00332/OnlineNewsPopularity.zip\")\n",
    "    open(\"./Data/OnlineNewsPopularity.zip\" , 'wb').write(r.content)\n",
    "\n",
    "if not os.path.exists(\"./Data/OnlineNewsPopularity.csv\") or not os.path.exists(\"./Data/OnlineNewsPopularity.names\"):\n",
    "    # unzip the file\n",
    "    with zipfile.ZipFile(\"./Data/OnlineNewsPopularity.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"./Data/OnlineNewsPopularity\")\n",
    "    \n",
    "    # change the location/tidy up\n",
    "    os.rename(\"./Data/OnlineNewsPopularity/OnlineNewsPopularity/OnlineNewsPopularity.csv\", \"./Data/OnlineNewsPopularity.csv\")\n",
    "    os.rename(\"./Data/OnlineNewsPopularity/OnlineNewsPopularity/OnlineNewsPopularity.names\", \"./Data/OnlineNewsPopularity.names\")\n",
    "    os.rmdir(\"./Data/OnlineNewsPopularity/OnlineNewsPopularity\")\n",
    "    os.rmdir(\"./Data/OnlineNewsPopularity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url   timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...       731.0   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...       731.0   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...       731.0   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...       731.0   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/       731.0   \n",
       "\n",
       "    n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n",
       "0             12.0              219.0          0.663594                1.0   \n",
       "1              9.0              255.0          0.604743                1.0   \n",
       "2              9.0              211.0          0.575130                1.0   \n",
       "3              9.0              531.0          0.503788                1.0   \n",
       "4             13.0             1072.0          0.415646                1.0   \n",
       "\n",
       "    n_non_stop_unique_tokens   num_hrefs   num_self_hrefs   num_imgs  ...  \\\n",
       "0                   0.815385         4.0              2.0        1.0  ...   \n",
       "1                   0.791946         3.0              1.0        1.0  ...   \n",
       "2                   0.663866         3.0              1.0        1.0  ...   \n",
       "3                   0.665635         9.0              0.0        1.0  ...   \n",
       "4                   0.540890        19.0             19.0       20.0  ...   \n",
       "\n",
       "    min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n",
       "0                0.100000                     0.7               -0.350000   \n",
       "1                0.033333                     0.7               -0.118750   \n",
       "2                0.100000                     1.0               -0.466667   \n",
       "3                0.136364                     0.8               -0.369697   \n",
       "4                0.033333                     1.0               -0.220192   \n",
       "\n",
       "    min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n",
       "0                  -0.600               -0.200000             0.500000   \n",
       "1                  -0.125               -0.100000             0.000000   \n",
       "2                  -0.800               -0.133333             0.000000   \n",
       "3                  -0.600               -0.166667             0.000000   \n",
       "4                  -0.500               -0.050000             0.454545   \n",
       "\n",
       "    title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "0                  -0.187500                 0.000000   \n",
       "1                   0.000000                 0.500000   \n",
       "2                   0.000000                 0.500000   \n",
       "3                   0.000000                 0.500000   \n",
       "4                   0.136364                 0.045455   \n",
       "\n",
       "    abs_title_sentiment_polarity   shares  \n",
       "0                       0.187500      593  \n",
       "1                       0.000000      711  \n",
       "2                       0.000000     1500  \n",
       "3                       0.000000     1200  \n",
       "4                       0.136364      505  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.read_csv(\"./Data/OnlineNewsPopularity.csv\")\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0. url:                           URL of the article\n",
      "\n",
      "     1. timedelta:                     Days between the article publication and\n",
      "\n",
      "                                       the dataset acquisition\n",
      "\n",
      "     2. n_tokens_title:                Number of words in the title\n",
      "\n",
      "     3. n_tokens_content:              Number of words in the content\n",
      "\n",
      "     4. n_unique_tokens:               Rate of unique words in the content\n",
      "\n",
      "     5. n_non_stop_words:              Rate of non-stop words in the content\n",
      "\n",
      "     6. n_non_stop_unique_tokens:      Rate of unique non-stop words in the\n",
      "\n",
      "                                       content\n",
      "\n",
      "     7. num_hrefs:                     Number of links\n",
      "\n",
      "     8. num_self_hrefs:                Number of links to other articles\n",
      "\n",
      "                                       published by Mashable\n",
      "\n",
      "     9. num_imgs:                      Number of images\n",
      "\n",
      "    10. num_videos:                    Number of videos\n",
      "\n",
      "    11. average_token_length:          Average length of the words in the\n",
      "\n",
      "                                       content\n",
      "\n",
      "    12. num_keywords:                  Number of keywords in the metadata\n",
      "\n",
      "    13. data_channel_is_lifestyle:     Is data channel 'Lifestyle'?\n",
      "\n",
      "    14. data_channel_is_entertainment: Is data channel 'Entertainment'?\n",
      "\n",
      "    15. data_channel_is_bus:           Is data channel 'Business'?\n",
      "\n",
      "    16. data_channel_is_socmed:        Is data channel 'Social Media'?\n",
      "\n",
      "    17. data_channel_is_tech:          Is data channel 'Tech'?\n",
      "\n",
      "    18. data_channel_is_world:         Is data channel 'World'?\n",
      "\n",
      "    19. kw_min_min:                    Worst keyword (min. shares)\n",
      "\n",
      "    20. kw_max_min:                    Worst keyword (max. shares)\n",
      "\n",
      "    21. kw_avg_min:                    Worst keyword (avg. shares)\n",
      "\n",
      "    22. kw_min_max:                    Best keyword (min. shares)\n",
      "\n",
      "    23. kw_max_max:                    Best keyword (max. shares)\n",
      "\n",
      "    24. kw_avg_max:                    Best keyword (avg. shares)\n",
      "\n",
      "    25. kw_min_avg:                    Avg. keyword (min. shares)\n",
      "\n",
      "    26. kw_max_avg:                    Avg. keyword (max. shares)\n",
      "\n",
      "    27. kw_avg_avg:                    Avg. keyword (avg. shares)\n",
      "\n",
      "    28. self_reference_min_shares:     Min. shares of referenced articles in\n",
      "\n",
      "                                       Mashable\n",
      "\n",
      "    29. self_reference_max_shares:     Max. shares of referenced articles in\n",
      "\n",
      "                                       Mashable\n",
      "\n",
      "    30. self_reference_avg_sharess:    Avg. shares of referenced articles in\n",
      "\n",
      "                                       Mashable\n",
      "\n",
      "    31. weekday_is_monday:             Was the article published on a Monday?\n",
      "\n",
      "    32. weekday_is_tuesday:            Was the article published on a Tuesday?\n",
      "\n",
      "    33. weekday_is_wednesday:          Was the article published on a Wednesday?\n",
      "\n",
      "    34. weekday_is_thursday:           Was the article published on a Thursday?\n",
      "\n",
      "    35. weekday_is_friday:             Was the article published on a Friday?\n",
      "\n",
      "    36. weekday_is_saturday:           Was the article published on a Saturday?\n",
      "\n",
      "    37. weekday_is_sunday:             Was the article published on a Sunday?\n",
      "\n",
      "    38. is_weekend:                    Was the article published on the weekend?\n",
      "\n",
      "    39. LDA_00:                        Closeness to LDA topic 0\n",
      "\n",
      "    40. LDA_01:                        Closeness to LDA topic 1\n",
      "\n",
      "    41. LDA_02:                        Closeness to LDA topic 2\n",
      "\n",
      "    42. LDA_03:                        Closeness to LDA topic 3\n",
      "\n",
      "    43. LDA_04:                        Closeness to LDA topic 4\n",
      "\n",
      "    44. global_subjectivity:           Text subjectivity\n",
      "\n",
      "    45. global_sentiment_polarity:     Text sentiment polarity\n",
      "\n",
      "    46. global_rate_positive_words:    Rate of positive words in the content\n",
      "\n",
      "    47. global_rate_negative_words:    Rate of negative words in the content\n",
      "\n",
      "    48. rate_positive_words:           Rate of positive words among non-neutral\n",
      "\n",
      "                                       tokens\n",
      "\n",
      "    49. rate_negative_words:           Rate of negative words among non-neutral\n",
      "\n",
      "                                       tokens\n",
      "\n",
      "    50. avg_positive_polarity:         Avg. polarity of positive words\n",
      "\n",
      "    51. min_positive_polarity:         Min. polarity of positive words\n",
      "\n",
      "    52. max_positive_polarity:         Max. polarity of positive words\n",
      "\n",
      "    53. avg_negative_polarity:         Avg. polarity of negative  words\n",
      "\n",
      "    54. min_negative_polarity:         Min. polarity of negative  words\n",
      "\n",
      "    55. max_negative_polarity:         Max. polarity of negative  words\n",
      "\n",
      "    56. title_subjectivity:            Title subjectivity\n",
      "\n",
      "    57. title_sentiment_polarity:      Title polarity\n",
      "\n",
      "    58. abs_title_subjectivity:        Absolute subjectivity level\n",
      "\n",
      "    59. abs_title_sentiment_polarity:  Absolute polarity level\n",
      "\n",
      "    60. shares:                        Number of shares (target)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data dictionary\n",
    "news_info = open(\"./Data/OnlineNewsPopularity.names\", \"r\")\n",
    "for i, line in enumerate(news_info):\n",
    "    if i>40 and i<111:\n",
    "        print(line)\n",
    "\n",
    "news_info.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove spaces in columns name character\n",
    "news_df.columns = news_df.columns.str.replace(' ', '')\n",
    "# remove the non-predictive information from the data\n",
    "news_df.drop([\"url\", \"timedelta\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29733, 58)\n",
      "(29733,)\n",
      "(9911, 58)\n",
      "(9911,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(news_df, random_state=42)\n",
    "\n",
    "X_train, y_train = train_set.drop(\"shares\", axis=1), train_set[\"shares\"]\n",
    "X_test, y_test = test_set.drop(\"shares\", axis=1), test_set[\"shares\"]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest class proportion: 0.058\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  val_score  train_score\n",
       "fold                                              \n",
       "0         0.01         0.0       -0.0          0.0\n",
       "1         0.00         0.0       -0.0          0.0\n",
       "2         0.01         0.0       -0.0          0.0\n",
       "3         0.01         0.0       -0.0          0.0\n",
       "4         0.01         0.0       -0.0          0.0\n",
       "mean      0.01         0.0       -0.0          0.0\n",
       "sd        0.00         0.0        0.0          0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# tidy the output into a dataframe\n",
    "def tidy_scores(score_dict):\n",
    "    df = pd.DataFrame(score_dict)\n",
    "    df.loc['mean'] = df.mean()\n",
    "    df.loc['sd'] = df.std()\n",
    "    df.rename({\"test_score\":\"val_score\"}, axis=1, inplace=True)\n",
    "    df.index.name = \"fold\"\n",
    "    return df.round(2)\n",
    "\n",
    "print(\"Highest class proportion: \" + str(round(pd.Series(y_train).value_counts(normalize=True).max(), 3)))\n",
    "\n",
    "scores = cross_validate(DummyRegressor(), X_train, y_train, cv=5, return_train_score=True)\n",
    "tidy_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.67</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  val_score  train_score\n",
       "fold                                              \n",
       "0         0.09        0.01       0.01         0.03\n",
       "1         0.07        0.00       0.03         0.02\n",
       "2         0.06        0.00       0.04         0.02\n",
       "3         0.07        0.00       0.01         0.03\n",
       "4         0.07        0.00      -5.67         0.02\n",
       "mean      0.07        0.00      -1.12         0.02\n",
       "sd        0.01        0.00       2.28         0.00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#log_pipe = Pipeline(pre_processing)\n",
    "lin_pipe = LinearRegression()\n",
    "\n",
    "display(lin_pipe)\n",
    "\n",
    "tidy_scores(cross_validate(lin_pipe, X_train, y_train, cv=5, return_train_score=True, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cor</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LDA_02</th>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_token_length</th>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_04</th>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_01</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_negative_words</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_tuesday</th>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_thursday</th>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate_positive_words</th>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_00</th>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_friday</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_wednesday</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_min</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_max</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_max</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_tokens_content</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_sunday</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_monday</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_tokens_title</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_is_saturday</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_weekend</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_subjectivity</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_keywords</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_videos</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_min</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_min</th>\n",
       "      <td>0.031</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_subjectivity</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_min_avg</th>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_imgs</th>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_max_shares</th>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_max</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_min_shares</th>\n",
       "      <td>0.041</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_reference_avg_sharess</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_hrefs</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_max_avg</th>\n",
       "      <td>0.056</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA_03</th>\n",
       "      <td>0.084</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_avg_avg</th>\n",
       "      <td>0.102</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 cor  p-value\n",
       "LDA_02                        -0.060    0.000\n",
       "data_channel_is_world         -0.051    0.000\n",
       "avg_negative_polarity         -0.025    0.000\n",
       "average_token_length          -0.021    0.000\n",
       "max_negative_polarity         -0.019    0.001\n",
       "data_channel_is_bus           -0.017    0.003\n",
       "data_channel_is_entertainment -0.016    0.005\n",
       "LDA_04                        -0.014    0.014\n",
       "LDA_01                        -0.012    0.045\n",
       "rate_negative_words           -0.012    0.044\n",
       "data_channel_is_tech          -0.011    0.070\n",
       "weekday_is_tuesday            -0.011    0.054\n",
       "min_negative_polarity         -0.010    0.072\n",
       "weekday_is_thursday           -0.010    0.072\n",
       "rate_positive_words           -0.008    0.162\n",
       "LDA_00                        -0.004    0.487\n",
       "num_self_hrefs                -0.001    0.865\n",
       "weekday_is_friday             -0.001    0.890\n",
       "global_rate_negative_words    -0.000    0.941\n",
       "n_non_stop_unique_tokens       0.000    0.957\n",
       "min_positive_polarity          0.000    0.933\n",
       "weekday_is_wednesday          -0.000    0.985\n",
       "n_non_stop_words               0.001    0.910\n",
       "n_unique_tokens                0.001    0.874\n",
       "kw_min_min                     0.001    0.918\n",
       "global_rate_positive_words     0.002    0.706\n",
       "kw_min_max                     0.003    0.600\n",
       "abs_title_subjectivity         0.003    0.560\n",
       "kw_max_max                     0.004    0.472\n",
       "data_channel_is_socmed         0.006    0.330\n",
       "n_tokens_content               0.006    0.337\n",
       "weekday_is_sunday              0.007    0.242\n",
       "weekday_is_monday              0.008    0.180\n",
       "data_channel_is_lifestyle      0.008    0.161\n",
       "max_positive_polarity          0.009    0.104\n",
       "title_sentiment_polarity       0.011    0.048\n",
       "n_tokens_title                 0.012    0.043\n",
       "global_sentiment_polarity      0.012    0.038\n",
       "avg_positive_polarity          0.013    0.026\n",
       "weekday_is_saturday            0.017    0.004\n",
       "is_weekend                     0.017    0.003\n",
       "title_subjectivity             0.021    0.000\n",
       "num_keywords                   0.023    0.000\n",
       "num_videos                     0.024    0.000\n",
       "abs_title_sentiment_polarity   0.026    0.000\n",
       "kw_max_min                     0.030    0.000\n",
       "kw_avg_min                     0.031    0.000\n",
       "global_subjectivity            0.032    0.000\n",
       "kw_min_avg                     0.036    0.000\n",
       "num_imgs                       0.036    0.000\n",
       "self_reference_max_shares      0.039    0.000\n",
       "kw_avg_max                     0.040    0.000\n",
       "self_reference_min_shares      0.041    0.000\n",
       "self_reference_avg_sharess     0.044    0.000\n",
       "num_hrefs                      0.047    0.000\n",
       "kw_max_avg                     0.056    0.000\n",
       "LDA_03                         0.084    0.000\n",
       "kw_avg_avg                     0.102    0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "column_names = X_train.columns\n",
    "\n",
    "for i in range(X_train.shape[-1]):\n",
    "\n",
    "    corr = pd.DataFrame(stats.pearsonr(X_train.iloc[:,i], y_train), \n",
    "                        index = [\"cor\", \"p-value\"],\n",
    "                        columns = [column_names[i]])\n",
    "    if i ==0:\n",
    "        all_corr = corr\n",
    "    else:\n",
    "        all_corr = pd.concat([all_corr, corr], axis = 1)\n",
    "        \n",
    "display(all_corr.round(3).sort_values(by=\"cor\", axis=1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "      <th>kw_max_min</th>\n",
       "      <th>...</th>\n",
       "      <th>LDA_04</th>\n",
       "      <th>global_subjectivity</th>\n",
       "      <th>global_sentiment_polarity</th>\n",
       "      <th>rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>9.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.837004</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123169</td>\n",
       "      <td>0.434722</td>\n",
       "      <td>-0.106597</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.214583</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.358779</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124486</td>\n",
       "      <td>0.533107</td>\n",
       "      <td>0.110035</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.339526</td>\n",
       "      <td>-0.386420</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.091667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.078788</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.336765</td>\n",
       "      <td>0.048529</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32204</th>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.072110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.343841</td>\n",
       "      <td>0.055903</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.297987</td>\n",
       "      <td>-0.217628</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13041</th>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.095420</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.910532</td>\n",
       "      <td>0.453349</td>\n",
       "      <td>0.120298</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.292208</td>\n",
       "      <td>-0.270370</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_tokens_title  num_hrefs  num_imgs  num_videos  average_token_length  \\\n",
       "2361              9.0       37.0       8.0         1.0              5.837004   \n",
       "3480             10.0        7.0       1.0         0.0              4.358779   \n",
       "6758              9.0        4.0       0.0         1.0              5.078788   \n",
       "32204            10.0       13.0       1.0         0.0              5.072110   \n",
       "13041            12.0        7.0       0.0         1.0              4.095420   \n",
       "\n",
       "       num_keywords  data_channel_is_entertainment  data_channel_is_bus  \\\n",
       "2361            8.0                            0.0                  0.0   \n",
       "3480           10.0                            1.0                  0.0   \n",
       "6758            5.0                            1.0                  0.0   \n",
       "32204           4.0                            0.0                  0.0   \n",
       "13041           9.0                            0.0                  0.0   \n",
       "\n",
       "       data_channel_is_world  kw_max_min  ...    LDA_04  global_subjectivity  \\\n",
       "2361                     1.0       635.0  ...  0.123169             0.434722   \n",
       "3480                     0.0       634.0  ...  0.124486             0.533107   \n",
       "6758                     0.0       919.0  ...  0.040000             0.336765   \n",
       "32204                    1.0         0.0  ...  0.050003             0.343841   \n",
       "13041                    0.0       731.0  ...  0.910532             0.453349   \n",
       "\n",
       "       global_sentiment_polarity  rate_negative_words  avg_positive_polarity  \\\n",
       "2361                   -0.106597             0.800000               0.250000   \n",
       "3480                    0.110035             0.281250               0.339526   \n",
       "6758                    0.048529             0.428571               0.281250   \n",
       "32204                   0.055903             0.393939               0.297987   \n",
       "13041                   0.120298             0.230769               0.292208   \n",
       "\n",
       "       avg_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "2361               -0.214583              -0.100000               0.000   \n",
       "3480               -0.386420              -0.155556               0.850   \n",
       "6758               -0.100000              -0.050000               0.000   \n",
       "32204              -0.217628              -0.125000               0.175   \n",
       "13041              -0.270370              -0.155556               0.000   \n",
       "\n",
       "       title_sentiment_polarity  abs_title_sentiment_polarity  \n",
       "2361                   0.000000                      0.000000  \n",
       "3480                   0.091667                      0.091667  \n",
       "6758                   0.000000                      0.000000  \n",
       "32204                  0.000000                      0.000000  \n",
       "13041                  0.000000                      0.000000  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter only correlations stronger than .1 in either direction (positive or negative)\n",
    "corrs = all_corr.loc[\"p-value\"]<0.05\n",
    "pd.DataFrame(X_train.loc[:,corrs]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  val_score  train_score\n",
       "fold                                              \n",
       "0         0.04        0.00       0.01         0.03\n",
       "1         0.03        0.00       0.03         0.02\n",
       "2         0.04        0.01       0.04         0.02\n",
       "3         0.03        0.00       0.01         0.02\n",
       "4         0.03        0.01       0.04         0.02\n",
       "mean      0.03        0.01       0.02         0.02\n",
       "sd        0.00        0.00       0.01         0.00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidy_scores(cross_validate(lin_pipe, pd.DataFrame(X_train.loc[:,corrs]), y_train, cv=5, return_train_score=True, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2361     0\n",
       "3480     0\n",
       "6758     0\n",
       "32204    1\n",
       "13041    0\n",
       "        ..\n",
       "6265     0\n",
       "11284    1\n",
       "38158    1\n",
       "860      0\n",
       "15795    1\n",
       "Name: shares, Length: 29733, dtype: int32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_ = (y_train<1400)*1\n",
    "y_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  val_score  train_score\n",
       "fold                                              \n",
       "0         0.01         0.0       0.54         0.54\n",
       "1         0.01         0.0       0.54         0.54\n",
       "2         0.01         0.0       0.54         0.54\n",
       "3         0.02         0.0       0.54         0.54\n",
       "4         0.01         0.0       0.54         0.54\n",
       "mean      0.01         0.0       0.54         0.54\n",
       "sd        0.00         0.0       0.00         0.00"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "scores = cross_validate(DummyClassifier(), X_train, y_train_, cv=5, return_train_score=True)\n",
    "tidy_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.2s\n",
      "[CV] END .................................................... total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  val_score  train_score\n",
       "fold                                              \n",
       "0         0.30         0.0       0.58         0.59\n",
       "1         0.23         0.0       0.61         0.59\n",
       "2         0.28         0.0       0.59         0.59\n",
       "3         0.25         0.0       0.58         0.60\n",
       "4         0.21         0.0       0.60         0.59\n",
       "mean      0.25         0.0       0.59         0.59\n",
       "sd        0.03         0.0       0.01         0.00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#log_pipe = Pipeline(pre_processing)\n",
    "log_pipe = LogisticRegression()\n",
    "\n",
    "display(log_pipe)\n",
    "\n",
    "tidy_scores(cross_validate(log_pipe, X_train, y_train_, cv=5, return_train_score=True, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  val_score  train_score\n",
       "fold                                              \n",
       "0         0.16        0.00       0.57         0.56\n",
       "1         0.16        0.00       0.56         0.57\n",
       "2         0.14        0.01       0.56         0.57\n",
       "3         0.16        0.00       0.56         0.57\n",
       "4         0.15        0.00       0.57         0.57\n",
       "mean      0.15        0.00       0.57         0.57\n",
       "sd        0.01        0.00       0.00         0.00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#log_pipe = Pipeline(pre_processing)\n",
    "log_pipe = LogisticRegression()\n",
    "\n",
    "display(log_pipe)\n",
    "\n",
    "tidy_scores(cross_validate(log_pipe, pd.DataFrame(X_train.loc[:,corrs]), y_train_, cv=5, return_train_score=True, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.4s\n",
      "[CV] END .................................................... total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David_Elliott\\anaconda3\\envs\\Programming_Basics\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  val_score  train_score\n",
       "fold                                              \n",
       "0         2.52        0.04       0.58         0.57\n",
       "1         0.55        0.04       0.57         0.56\n",
       "2         0.46        0.04       0.56         0.56\n",
       "3         0.46        0.04       0.56         0.57\n",
       "4         0.52        0.05       0.56         0.56\n",
       "mean      0.90        0.05       0.56         0.57\n",
       "sd        0.81        0.00       0.01         0.00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(RandomForestClassifier(criterion='gini',\n",
    "                                                               n_estimators=10,\n",
    "                                                               max_features = 5,\n",
    "                                                               random_state=0,\n",
    "                                                               n_jobs=-1), \n",
    "                                        threshold = 'mean')),\n",
    "  ('classification', LogisticRegression())\n",
    "])\n",
    "\n",
    "tidy_scores(cross_validate(clf, X_train, y_train_, cv=5, return_train_score=True, verbose=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# divorse\n",
    "__Notes__ I had to use 7-zip to extract the data https://archive.ics.uci.edu/ml/machine-learning-databases/00497/divorce.rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atr1</th>\n",
       "      <th>Atr2</th>\n",
       "      <th>Atr3</th>\n",
       "      <th>Atr4</th>\n",
       "      <th>Atr5</th>\n",
       "      <th>Atr6</th>\n",
       "      <th>Atr7</th>\n",
       "      <th>Atr8</th>\n",
       "      <th>Atr9</th>\n",
       "      <th>Atr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Atr46</th>\n",
       "      <th>Atr47</th>\n",
       "      <th>Atr48</th>\n",
       "      <th>Atr49</th>\n",
       "      <th>Atr50</th>\n",
       "      <th>Atr51</th>\n",
       "      <th>Atr52</th>\n",
       "      <th>Atr53</th>\n",
       "      <th>Atr54</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Atr1  Atr2  Atr3  Atr4  Atr5  Atr6  Atr7  Atr8  Atr9  Atr10  ...  Atr46  \\\n",
       "0     2     2     4     1     0     0     0     0     0      0  ...      2   \n",
       "1     4     4     4     4     4     0     0     4     4      4  ...      2   \n",
       "2     2     2     2     2     1     3     2     1     1      2  ...      3   \n",
       "3     3     2     3     2     3     3     3     3     3      3  ...      2   \n",
       "4     2     2     1     1     1     1     0     0     0      0  ...      2   \n",
       "\n",
       "   Atr47  Atr48  Atr49  Atr50  Atr51  Atr52  Atr53  Atr54  Class  \n",
       "0      1      3      3      3      2      3      2      1      1  \n",
       "1      2      3      4      4      4      4      2      2      1  \n",
       "2      2      3      1      1      1      2      2      2      1  \n",
       "3      2      3      3      3      3      2      2      2      1  \n",
       "4      1      2      3      2      2      2      1      0      1  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divorse_df = pd.read_excel(\"./Data/divorce/divorce.xlsx\")\n",
    "divorse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 54)\n",
      "(127,)\n",
      "(43, 54)\n",
      "(43,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(divorse_df, random_state=42)\n",
    "\n",
    "X_train, y_train = train_set.drop(\"Class\", axis=1), train_set[\"Class\"]\n",
    "X_test, y_test = test_set.drop(\"Class\", axis=1), test_set[\"Class\"]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest class proportion: 0.52\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  val_score  train_score\n",
       "fold                                              \n",
       "0          0.0         0.0       0.54         0.51\n",
       "1          0.0         0.0       0.50         0.52\n",
       "2          0.0         0.0       0.52         0.52\n",
       "3          0.0         0.0       0.52         0.52\n",
       "4          0.0         0.0       0.52         0.52\n",
       "mean       0.0         0.0       0.52         0.52\n",
       "sd         0.0         0.0       0.01         0.00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# tidy the output into a dataframe\n",
    "def tidy_scores(score_dict):\n",
    "    df = pd.DataFrame(score_dict)\n",
    "    df.loc['mean'] = df.mean()\n",
    "    df.loc['sd'] = df.std()\n",
    "    df.rename({\"test_score\":\"val_score\"}, axis=1, inplace=True)\n",
    "    df.index.name = \"fold\"\n",
    "    return df.round(2)\n",
    "\n",
    "print(\"Highest class proportion: \" + str(round(pd.Series(y_train).value_counts(normalize=True).max(), 3)))\n",
    "\n",
    "scores = cross_validate(DummyClassifier(), X_train, y_train, cv=5, return_train_score=True)\n",
    "tidy_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  val_score  train_score\n",
       "fold                                              \n",
       "0         0.01         0.0       0.96          1.0\n",
       "1         0.01         0.0       0.96          1.0\n",
       "2         0.01         0.0       0.96          1.0\n",
       "3         0.01         0.0       1.00          1.0\n",
       "4         0.00         0.0       1.00          1.0\n",
       "mean      0.01         0.0       0.98          1.0\n",
       "sd        0.00         0.0       0.02          0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#log_pipe = Pipeline(pre_processing)\n",
    "log_pipe = LogisticRegression()\n",
    "\n",
    "display(log_pipe)\n",
    "\n",
    "tidy_scores(cross_validate(log_pipe, X_train, y_train, cv=5, return_train_score=True, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cor</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Atr6</th>\n",
       "      <td>0.445</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr46</th>\n",
       "      <td>0.473</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr45</th>\n",
       "      <td>0.539</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr43</th>\n",
       "      <td>0.541</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr7</th>\n",
       "      <td>0.572</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr48</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr52</th>\n",
       "      <td>0.614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr47</th>\n",
       "      <td>0.653</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr51</th>\n",
       "      <td>0.669</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr53</th>\n",
       "      <td>0.691</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr42</th>\n",
       "      <td>0.717</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr49</th>\n",
       "      <td>0.746</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr50</th>\n",
       "      <td>0.749</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr31</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr54</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr3</th>\n",
       "      <td>0.806</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr2</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr32</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr24</th>\n",
       "      <td>0.819</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr4</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr10</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr22</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr13</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr23</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr14</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr28</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr37</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr1</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr25</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr8</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr44</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr27</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr26</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr34</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr33</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr21</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr30</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr5</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr29</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr39</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr35</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr12</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr16</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr41</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr36</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr11</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr15</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr9</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr20</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr18</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr19</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr17</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr38</th>\n",
       "      <td>0.930</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atr40</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cor  p-value\n",
       "Atr6   0.445      0.0\n",
       "Atr46  0.473      0.0\n",
       "Atr45  0.539      0.0\n",
       "Atr43  0.541      0.0\n",
       "Atr7   0.572      0.0\n",
       "Atr48  0.585      0.0\n",
       "Atr52  0.614      0.0\n",
       "Atr47  0.653      0.0\n",
       "Atr51  0.669      0.0\n",
       "Atr53  0.691      0.0\n",
       "Atr42  0.717      0.0\n",
       "Atr49  0.746      0.0\n",
       "Atr50  0.749      0.0\n",
       "Atr31  0.786      0.0\n",
       "Atr54  0.803      0.0\n",
       "Atr3   0.806      0.0\n",
       "Atr2   0.810      0.0\n",
       "Atr32  0.819      0.0\n",
       "Atr24  0.819      0.0\n",
       "Atr4   0.824      0.0\n",
       "Atr10  0.834      0.0\n",
       "Atr22  0.839      0.0\n",
       "Atr13  0.841      0.0\n",
       "Atr23  0.841      0.0\n",
       "Atr14  0.846      0.0\n",
       "Atr28  0.849      0.0\n",
       "Atr37  0.851      0.0\n",
       "Atr1   0.851      0.0\n",
       "Atr25  0.855      0.0\n",
       "Atr8   0.858      0.0\n",
       "Atr44  0.858      0.0\n",
       "Atr27  0.859      0.0\n",
       "Atr26  0.863      0.0\n",
       "Atr34  0.865      0.0\n",
       "Atr33  0.872      0.0\n",
       "Atr21  0.875      0.0\n",
       "Atr30  0.878      0.0\n",
       "Atr5   0.881      0.0\n",
       "Atr29  0.882      0.0\n",
       "Atr39  0.885      0.0\n",
       "Atr35  0.886      0.0\n",
       "Atr12  0.888      0.0\n",
       "Atr16  0.894      0.0\n",
       "Atr41  0.894      0.0\n",
       "Atr36  0.906      0.0\n",
       "Atr11  0.907      0.0\n",
       "Atr15  0.910      0.0\n",
       "Atr9   0.910      0.0\n",
       "Atr20  0.911      0.0\n",
       "Atr18  0.914      0.0\n",
       "Atr19  0.925      0.0\n",
       "Atr17  0.925      0.0\n",
       "Atr38  0.930      0.0\n",
       "Atr40  0.946      0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "column_names = X_train.columns\n",
    "\n",
    "for i in range(X_train.shape[-1]):\n",
    "\n",
    "    corr = pd.DataFrame(stats.pearsonr(X_train.iloc[:,i], y_train), \n",
    "                        index = [\"cor\", \"p-value\"],\n",
    "                        columns = [column_names[i]])\n",
    "    if i ==0:\n",
    "        all_corr = corr\n",
    "    else:\n",
    "        all_corr = pd.concat([all_corr, corr], axis = 1)\n",
    "        \n",
    "display(all_corr.round(3).sort_values(by=\"cor\", axis=1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atr9</th>\n",
       "      <th>Atr11</th>\n",
       "      <th>Atr15</th>\n",
       "      <th>Atr17</th>\n",
       "      <th>Atr18</th>\n",
       "      <th>Atr19</th>\n",
       "      <th>Atr20</th>\n",
       "      <th>Atr36</th>\n",
       "      <th>Atr38</th>\n",
       "      <th>Atr40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Atr9  Atr11  Atr15  Atr17  Atr18  Atr19  Atr20  Atr36  Atr38  Atr40\n",
       "146     0      0      0      1      0      1      0      0      0      1\n",
       "137     1      0      0      0      0      0      0      0      0      0\n",
       "97      0      0      0      0      0      0      0      0      0      0\n",
       "65      3      3      3      3      3      3      3      3      3      3\n",
       "36      3      4      3      4      3      4      3      3      4      4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter only correlations stronger than .1 in either direction (positive or negative)\n",
    "corrs = all_corr.loc[\"cor\"]>0.9\n",
    "pd.DataFrame(X_train.loc[:,corrs]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  val_score  train_score\n",
       "fold                                              \n",
       "0         0.00         0.0       0.96         1.00\n",
       "1         0.01         0.0       0.96         0.99\n",
       "2         0.01         0.0       1.00         0.99\n",
       "3         0.01         0.0       1.00         0.99\n",
       "4         0.00         0.0       1.00         0.99\n",
       "mean      0.01         0.0       0.98         0.99\n",
       "sd        0.00         0.0       0.02         0.00"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#log_pipe = Pipeline(pre_processing)\n",
    "log_pipe = LogisticRegression()\n",
    "\n",
    "display(log_pipe)\n",
    "\n",
    "tidy_scores(cross_validate(log_pipe, pd.DataFrame(X_train.loc[:,corrs]), y_train, cv=5, return_train_score=True, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "mi = mutual_info_classif(X_train, y_train)\n",
    "mi_series = pd.Series(mi, index=X_train.columns).sort_values(ascending = False)\n",
    "\n",
    "# lets plot the top 30\n",
    "PLOT_NUM = 54\n",
    "mi_series[:PLOT_NUM].plot.bar(legend = False, figsize=(15,10))\n",
    "plt.title('Mutual information (' + str(PLOT_NUM) + ')')\n",
    "\n",
    "plt.xticks(rotation=45,ha='right')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('mutual_information.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atr12</th>\n",
       "      <th>Atr16</th>\n",
       "      <th>Atr17</th>\n",
       "      <th>Atr18</th>\n",
       "      <th>Atr19</th>\n",
       "      <th>Atr20</th>\n",
       "      <th>Atr36</th>\n",
       "      <th>Atr38</th>\n",
       "      <th>Atr40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Atr12  Atr16  Atr17  Atr18  Atr19  Atr20  Atr36  Atr38  Atr40\n",
       "146      1      0      1      0      1      0      0      0      1\n",
       "137      0      0      0      0      0      0      0      0      0\n",
       "97       0      0      0      0      0      0      0      0      0\n",
       "65       3      2      3      3      3      3      3      3      3\n",
       "36       3      3      4      3      4      3      3      4      4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter only correlations stronger than .1 in either direction (positive or negative)\n",
    "mis = mi_series>0.6\n",
    "pd.DataFrame(X_train.loc[:,mis]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  val_score  train_score\n",
       "fold                                              \n",
       "0         0.01         0.0       0.96         1.00\n",
       "1         0.00         0.0       0.96         0.99\n",
       "2         0.00         0.0       0.96         0.99\n",
       "3         0.00         0.0       1.00         0.99\n",
       "4         0.01         0.0       1.00         0.99\n",
       "mean      0.00         0.0       0.98         0.99\n",
       "sd        0.00         0.0       0.02         0.00"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidy_scores(cross_validate(log_pipe, pd.DataFrame(X_train.loc[:,mis]), y_train, cv=5, return_train_score=True, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Clustering.ipynb",
   "provenance": []
  },
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
